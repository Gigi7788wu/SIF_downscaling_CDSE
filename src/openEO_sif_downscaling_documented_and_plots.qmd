---
title: "SIF Downscaling using OpenEO and the Copernicus Data Space Ecosystem (CDSE)"
format:
  html:
    toc: true
    toc-location: left
css: styles.css
jupyter: python3
toc: true
toc-depth: 2
toc-title: Contents
author: Daniel E. Pabon-Moreno, Qiqi Deng, Gregory Duveiller.
email: dpabon@bgc-jena.mpg.de

---
## Introduction

In the following example we will Downscaled (Increase the spatial resolution) of Sun Induced Fluorescence product derived from Sentinel-5p TROPOMI sensor. A full workflow diagram is presented here: XXXXX

## Libraries
We will need the following libraries to run dowscaling processor
```{python}
import openeo
import rioxarray as rio

"""
Currently there is an issue with openEO back-end that doesnt allow us to upsample datacubes (For more details see [here](https://forum.dataspace.copernicus.eu/t/how-to-spatial-upsampling-when-using-resample-cube-spatial/4358/6)). For this reason we will need some other libraries to process the parameters cube locally, perform a spatial upsample, create a stac catalog and publish the file and catalog on github.
This is needed to create a STAC item for the upsampled parameters:
"""
import pystac
from pystac.extensions.projection import ProjectionExtension
from pystac.extensions.eo import EOExtension
from datetime import datetime
from shapely.geometry import box, mapping
import json
import subprocess

# For data visualization
import xarray as xr
import matplotlib.pyplot as plt

# For spatial resampling
import xesmf as xe
import xarray_regrid
import numpy as np
```

## Area of Interest and Time Period

Before going into the details of the datasets we need to define an area of interest and time period of our analysis. For this example we will focus in south part of Spain in the period between 2023-07-17 and 2023-07-23.

```{python}
spatial_extent_prototype = {
    "west": -7.0,
    "east": -1.0,
    "south": 37.0,
    "north": 40.0,
}

temporal_extent_prototype = ["2023-07-17", "2023-07-23"]
```

```{python}
# | echo: false
import cartopy.crs as ccrs
import cartopy.feature as cfeature
from matplotlib.patches import Rectangle


def plot_world_with_bbox(bbox, title="World Map with Bounding Box"):
    """
    Plot world map with a bounding box overlay.

    Parameters:
    -----------
    bbox : tuple or list
        Bounding box coordinates as (min_lon, min_lat, max_lon, max_lat)
    title : str
        Plot title
    """
    min_lon, min_lat, max_lon, max_lat = (
        bbox["west"],
        bbox["south"],
        bbox["east"],
        bbox["north"],
    )

    # Create figure and axis with PlateCarree projection
    fig, ax = plt.subplots(
        figsize=(15, 10), subplot_kw={"projection": ccrs.PlateCarree()}
    )

    # Add map features
    ax.add_feature(cfeature.LAND, facecolor="lightgray", edgecolor="none")
    ax.add_feature(cfeature.OCEAN, facecolor="lightblue")
    ax.add_feature(cfeature.COASTLINE, linewidth=0.5)
    ax.add_feature(cfeature.BORDERS, linewidth=0.3, linestyle=":")
    ax.add_feature(
        cfeature.LAKES, facecolor="lightblue", edgecolor="black", linewidth=0.3
    )

    # Add gridlines
    gl = ax.gridlines(
        draw_labels=True, linewidth=0.5, color="gray", alpha=0.5, linestyle="--"
    )
    gl.top_labels = False
    gl.right_labels = False

    # Set global extent
    ax.set_global()

    # Draw bounding box
    width = max_lon - min_lon
    height = max_lat - min_lat

    bbox_patch = Rectangle(
        (min_lon, min_lat),
        width,
        height,
        linewidth=2,
        edgecolor="red",
        facecolor="none",
        transform=ccrs.PlateCarree(),
        zorder=5,
    )
    ax.add_patch(bbox_patch)

    # Add a label for the bbox
    center_lon = (min_lon + max_lon) / 2
    center_lat = (min_lat + max_lat) / 2
    ax.text(
        center_lon,
        max_lat + 5,
        "Area of Interest",
        transform=ccrs.PlateCarree(),
        ha="center",
        fontsize=10,
        color="red",
        weight="bold",
    )

    ax.set_title(title, fontsize=14, weight="bold", pad=20)

    plt.tight_layout()
    return fig, ax


fig1, ax1 = plot_world_with_bbox(spatial_extent_prototype, " ")

plt.show()

```

## Connecting to CDSE using openEO

To connect to the openEO insfrastructure in the CDSE we need to create a connection:

::: {.callout-important}
If you're using Positron to run this tutorial please first open the ```authentication.ipynb``` notebook run the cells there, and follow the instructions. This step is only necessary once, the next time you run the cells of this tutorial openeo will use refresh authentication tokens.
:::

```{python}
connection = openeo.connect(
    "https://openeofed.dataspace.copernicus.eu/"
)

connection.authenticate_oidc()
```

This will open a tab in the web-browser where the user needs to authenticate using the CDSE credentials. For more details on openEO in CDSE please see: [https://dataspace.copernicus.eu/analyse/openeo](https://dataspace.copernicus.eu/analyse/openeo)

Then we can see the data collections that are available:

```{python}
# | eval: false

connection.list_collections()
```

:::{.scrolling}

```{python}
# | echo: false

connection.list_collections()
```

:::


## Variables

For this tutorial we will use the following datasets/variables:

Target:

| Variable name | Collection | Band Name | Spatial resolution|
|--|--|--|--|
|Sun-Induced Flourescence| [Dong Li SIF](https://raw.githubusercontent.com/dpabon/SIF_downscaling_CDSE/refs/heads/main/data/SIF_20180629.json)| ```SIF```| 5 km |

Currently there are two SIF gridded products derived from Sentinel-5p that are availables:

1. [S5P-PAL SIF](https://data-portal.s5p-pal.com/products/troposif.html). This product is generated by the Sentinel-5P Product Algorithm Laboratory (S5P-PAL) and contains modified Copernicus Sentinel data processed by S[&]T. Unfortunately, the current (at least at: 2025-12-01) STAC dissemination only include plain netcdf files and not cloud optimized data format. Currently the [Atmosphere Virtual Lab project](https://atmospherevirtuallab.org/) is working in provided zarr datacubes for the L3 products, including SIF.

2. [Dong LI SIF](https://www.sciencedirect.com/science/article/pii/S0034425725003918#da0005). This product uses an artificial neural network to retrieve SIF from Sentinel-5p observations. Thanks to Dong Li for provinding us with a [gridded example of the product](https://github.com/dpabon/SIF_downscaling_CDSE/blob/main/data/SIF_20180629.tif) and the [stac item](https://github.com/dpabon/SIF_downscaling_CDSE/blob/main/data/SIF_20180629.json) necessary to ingest the product in the openEO-CDSE infrastructure. This files can be found in the data directory of the [repository](https://github.com/dpabon/SIF_downscaling_CDSE).

Predictors:

| Variable name | Collection | Band Name | Spatial resolution |
|--|--|--|--|
|Land Surface Temperature| ```SENTINEL3_SLSTR_L2_LST```| ```LST```| 1 km|
|Near Infrared Vegetation Index| ```SENTINEL3_OLCI_L2_LAND```| ```RC681```, ```RC865```| 300 m|
: SIF predictors {#tbl-predictors}

### Creating openEO datacubes for the variables



```{python}

# Testing SIF - Dong Li

cube_SIF_original_median = connection.load_stac(
    "https://raw.githubusercontent.com/dpabon/SIF_downscaling_CDSE/refs/heads/main/data/2023-07-SIF/SIF_20230720.json",
    bands=["SIF"],
    spatial_extent=spatial_extent_prototype,
    temporal_extent=temporal_extent_prototype,
)


cube_LST = connection.load_collection(
    "SENTINEL3_SLSTR_L2_LST",
    spatial_extent=spatial_extent_prototype,
    temporal_extent=temporal_extent_prototype,
    bands=["LST"],
)

cube_LST_qc = connection.load_collection(
    "SENTINEL3_SLSTR_L2_LST",
    spatial_extent=spatial_extent_prototype,
    temporal_extent=temporal_extent_prototype,
    bands=["confidence_in"],
)

red = connection.load_collection(
    "SENTINEL3_OLCI_L2_LAND",
    spatial_extent=spatial_extent_prototype,
    temporal_extent=temporal_extent_prototype,
    bands=["RC681"],
)

nir = connection.load_collection(
    "SENTINEL3_OLCI_L2_LAND",
    spatial_extent=spatial_extent_prototype,
    temporal_extent=temporal_extent_prototype,
    bands=["RC865"],
)

cube_NIRv = ((nir - red) / (nir + red)) * nir

cube_NIRv = cube_NIRv.rename_labels(dimension="bands", target=["NIRv"])

cube_OLCI_qc = connection.load_collection(
    "SENTINEL3_OLCI_L2_LAND",
    spatial_extent=spatial_extent_prototype,
    temporal_extent=temporal_extent_prototype,
    bands=["LQSF"],
)

```




### Masking clouds


```{python}

mask = cube_LST_qc > 5000

cube_LST_masked = cube_LST.mask(mask)

```

```{python}

mask_olci = cube_OLCI_qc > 10000

cube_NIRv_masked = cube_NIRv.mask(mask_olci)
```


If we call one of the cubes we can see the process graph that is created by openEO:
 
```{python}
cube_LST_masked
```

## Reducing the time dimension

For this analysis we will compute a composite of the area of interest using all the observations during the time period for all the variables except SIF that is already one time step observation.

```{python}

cube_LST_median = cube_LST_masked.reduce_temporal(reducer="max")

cube_NIRv_median = cube_NIRv_masked.reduce_temporal(reducer="median")

```


```{python}
cube_LST_median
```

## Inspecting the variables

Then we will inspect the products, for that we need to execute the processors for each cube, save it locally, open and plot.


```{python}
# cube_SIF_original_median.execute_batch(outputfile="data/cube_SIF_median.tif")
# cube_LST_median.execute_batch(outputfile="data/cube_LST_median.tif")
# cube_NIRv_median.execute_batch(outputfile="data/cube_NIRv_median.tif")
```


```{python}
cube_sif_local = rio.open_rasterio(
    filename="data/cube_SIF_median.tif", mask_and_scale=True
)
cube_lst_local = rio.open_rasterio(filename="data/cube_LST_median.tif")
cube_nirv_local = rio.open_rasterio(filename="data/cube_NIRv_median.tif")

```

```{python}
fig, axs = plt.subplots(nrows=3, figsize=(6, 15))
cube_sif_local.plot(ax=axs[0])
axs[0].set_title("SIF")
cube_lst_local.plot(ax=axs[1])
axs[1].set_title("LST")
cube_nirv_local.plot(ax=axs[2])
axs[2].set_title("NIRv")

plt.tight_layout()
plt.close()
```



## Spatial resampling to match the SIF resolution product


```{python}
cube_LST_median_low = cube_LST_median.resample_cube_spatial(
    target=cube_SIF_original_median, method="med"
)

cube_NIRv_median_low = cube_NIRv_median.resample_cube_spatial(
    target=cube_SIF_original_median, method="med"
)

```


```{python}
cube_LST_median_low
```

Merging all the cubes at low resolution (SIF original resolution)

```{python}
dataset_SIF_low = cube_SIF_original_median.merge_cubes(cube_LST_median_low)

dataset_SIF_low = dataset_SIF_low.merge_cubes(cube_NIRv_median_low)

```



Adding two dummy variables to the datacube to match the number of oputput parameters of the optimization function.

```{python}
dataset_SIF_low = dataset_SIF_low.merge_cubes(
    other=cube_SIF_original_median.rename_labels(dimension="bands", target=["dummy_1"])
)
dataset_SIF_low = dataset_SIF_low.merge_cubes(
    other=cube_SIF_original_median.rename_labels(dimension="bands", target=["dummy_2"])
)
```

```{python}
# | eval: false
# dataset_SIF_low.execute_batch(outputfile="data/sif_predictors_cube_low.nc")
```

Let's check the cube after resampling

```{python}
dataset_sif_low_local = xr.open_dataset("data/sif_predictors_cube_low.nc")
print(dataset_sif_low_local)
```

```{python}
fig, axs = plt.subplots(nrows=3, figsize=(6, 15))
dataset_sif_low_local["SIF"].plot(ax=axs[0])
axs[0].set_title("SIF")
dataset_sif_low_local["LST"].plot(ax=axs[1])
axs[1].set_title("LST")
dataset_sif_low_local["NIRv"].plot(ax=axs[2])
axs[2].set_title("NIRv")
plt.tight_layout()
plt.close()
```


## SIF parameter optimization at low spatial resolution

To predict SIF we use the following formulation:

::: {#def-sif}
$$SIF = f(V) \cdot f(T)$$
:::

where $f(V)$ represents the vegetation module and $V$ is a vegation index: 
$$f(V) = b_2 \cdot V^{b_1}$$


$f(T)$ represents the temperature module where $T$ is a variable that represent temperature stress (e.g. air temperature at 2 meters, or land surface temperature)

$$
f(T) = e^{-\frac{(T + b_5)^2}{2b_6^2}}
$$


Given the previous formulation we optimize the function using L-BFGS-B and a spatial moving window with 40 observations. The optimization function is defined in [udf_parameters_optim_low_res.py](https://github.com/dpabon/SIF_downscaling_CDSE/blob/main/sif_downscaling_openEO_CDSE/udf/udf_parameters_optim_low_res.py).

First we need to define the boundaries and start values for $b1$, $b2$, $b5$ $b6$ parameters:

```{python}
# the order for each variable follows: b1,b2,b3,b4,b5,b6

param_min = [0, 0.1, -310, 1]

param_ini = [1, 2, -295, 10]

param_max = [1.5, 5, -290, 50]
```


To apply the optimization function in the data cube we define an openEO User Define Function using:

```{python}
my_udf = openeo.UDF.from_file(
    "src/udf/udf_parameters_optim_low_res.py",
    context={
        "param_ini": param_ini,
        "param_min": param_min,
        "param_max": param_max,
        "min_obs": 21,
        "window_size_lat": 5,
        "window_size_lon": 5,
    },
)

```

Notice that the size of the moving window is set using ```window_size_lat``` and ```window_size_lon```.

Then we can apply our function to the data cube using:
```{python}

parameters_cube_low = dataset_SIF_low.apply_neighborhood(
    process=my_udf,
    size=[
        {"dimension": "x", "value": 512, "unit": "px"},
        {"dimension": "y", "value": 512, "unit": "px"},
    ],
    overlap=[
        {"dimension": "x", "value": 0, "unit": "px"},
        {"dimension": "y", "value": 0, "unit": "px"},
    ],
)

# changing the name of the ouput
output_bands = ["b1", "b2", "b5", "b6"]

parameters_cube_low_rename = parameters_cube_low.rename_labels("bands", output_bands)

```

and see the process graph:
```{python}
parameters_cube_low_rename
```

Now we will download the cube the optimized parameters to have a look and spatially upsample to match the Sentinel-3 cube at high resolution.

```{python}
# | eval: false
"""
parameters_cube_low_rename.execute_batch(outputfile="data/results_parameters_optim_low_resolution.tif")
"""
```

## Checking parameter optimization results


```{python}
parameters_cube_local = rio.open_rasterio(
    "data/results_parameters_optim_low_resolution.tif"
)
print(parameters_cube_local)
```

```{python}
# plt.clf()
fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(8, 6))
axs = axs.flatten()
counter = 0
for i in [1, 2, 5, 6]:
    parameters_cube_local.isel(band=counter).plot(ax=axs[counter])
    axs[counter].set_title(f"b{i}")
    counter += 1

plt.tight_layout()

```

....

## Resampling OLCI products at 1 km

Originally the OLCI products are 300 meters resolution, as Sentinel-3 LST product is at 1 km (@tbl-predictors) we need to resample the NIRv cube:

```{python}
cube_NIRv_median_1 = cube_NIRv_median.resample_cube_spatial(
    target=cube_LST_median, method="med"
)
```

```{python}
# | eval: false
"""
cube_NIRv_median_1.execute_batch("data/cube_nirv_1km_mask.tif")
"""
```

# Upsampling the parameters cube

::: {.callout-note}

Until openEO team solve the upsampling issue. For details see [CDSE discusion forum](https://forum.dataspace.copernicus.eu/t/how-to-spatial-upsampling-when-using-resample-cube-spatial/4358/6) We need to make a workaround to upsample the parameters cube.

:::

This is a temporary solution
```{python}
# | code-fold: true
# | eval: false

parameters_low = rio.open_rasterio("data/results_parameters_optim_low_resolution.tif")

parameters_low = parameters_low.drop_vars("spatial_ref")


# LST high resolution local
nirv_high = rio.open_rasterio("data/cube_nirv_1km_mask.tif")

nirv_high = nirv_high.drop_vars(["spatial_ref", "band"])



parameters_high = parameters_low.regrid.conservative(nirv_high)

parameters_high_2 = xr.DataArray(parameters_high.data.todense(), coords=parameters_high.coords)

# Saving the resample raster

parameters_high_2.rio.to_raster("data/results_paramaters_high_resolution.tif")
```

```{python}
# plt.clf()
fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(8, 6))
axs = axs.flatten()
counter = 0
for i in [1, 2, 5, 6]:
    parameters_high.isel(band=counter).plot(ax=axs[counter])
    axs[counter].set_title(f"b{i}")
    counter += 1

plt.tight_layout()

```

::: {.callout-important}
Change the following path accordindly to your github repository.
:::

```{python}
# | code-fold: true
# | eval: false

output_path = "https://github.com/dpabon/SIF_downscaling_CDSE/raw/refs/heads/main/data/results_paramaters_high_resolution.tif"
```

```{python}
# | code-fold: true
# | eval: false

# Get metadata from the raster
bbox = list(parameters_high.rio.bounds())  # [minx, miny, maxx, maxy]
epsg = "4326"
shape = [parameters_high.rio.height, parameters_high.rio.width]

# Create geometry from bbox
geom = mapping(box(*bbox))

# Create the STAC item
item = pystac.Item(
    id="results_parameters_high_resolution",
    geometry=geom,
    bbox=bbox,
    datetime=datetime.strptime(temporal_extent_prototype[0], "%Y-%m-%d"),
    properties={},
)

# Add projection extension
proj_ext = ProjectionExtension.ext(item, add_if_missing=True)
proj_ext.epsg = epsg
proj_ext.shape = shape
proj_ext.bbox = bbox

# Add EO extension
EOExtension.ext(item, add_if_missing=True)

# Add the asset
item.add_asset(
    key="parameters",
    asset=pystac.Asset(
        href=output_path,  # or use an absolute path / URL
        title="Optimized Parameters High Resolution",
        media_type="image/tiff; application=geotiff",
        extra_fields={"eo:bands": [{"name": f"b{i}"} for i in [1, 2, 5, 6]]},
    ),
)


# Save as JSON

with open("data/results_parameters_high_resolution.json", "w") as f:
    json.dump(item.to_dict(), f, indent=2)

print(item.to_dict())

# pushing changes to the remote repo to access from openEO again

git_commit = ["git", "commit", "-m", '"Upsampling of parameters updated"', "-a"]

subprocess.run(git_commit)

git_push = ["git", "push"]

subprocess.run(git_push)

# plotting the resampled parameters

fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(8, 8))
axs = axs.flatten()

for i in range(4):
    parameters_high.sel(band=i + 1).plot(ax=axs[i])
    axs[i].set_title(f"b{i + 1}")

plt.tight_layout()

```


Once the upsampling functionality is part of openEO one should be able to do:

```{python}
# | eval: false
"""
parameters_cube_high = parameters_cube_low_rename.resample_cube_spatial(
    target=cube_LST_median
)
"""
```

Meanwhile we can use ```load_stac``` to load again the parameters cube in openEO.


```{python}
parameters_cube_high = connection.load_stac(
    "https://raw.githubusercontent.com/dpabon/SIF_downscaling_CDSE/refs/heads/main/data/results_parameters_high_resolution.json",
    spatial_extent=spatial_extent_prototype,
    temporal_extent=temporal_extent_prototype,
    bands=["b1", "b2", "b5", "b6"],
)
parameters_cube_high


# parameters_cube_high_median = parameters_cube_high.reduce_temporal("median")
parameters_cube_high_median = parameters_cube_high
```



Then, we can concatenate all the variables in a single cube for prediction:

```{python}
cube_to_upscale = parameters_cube_high_median.merge_cubes(cube_LST_median)

cube_to_upscale = cube_to_upscale.merge_cubes(cube_NIRv_median_1)

```

```{python}
# | eval: false
# cube_to_upscale.execute_batch(outputfile="data/sif_predictors_cube_high.tif")
```

Checking that everything is in order with the code to upscale
```{python}
cube_to_upscale_local = xr.open_dataset("data/sif_predictors_cube_high.tif")

print(cube_to_upscale_local)
```


## Downscaling SIF

To downscale SIF we will use @def-sif. The code implementation of @def-sif is available at [udf_sif_downscaling.py](https://github.com/dpabon/SIF_downscaling_CDSE/blob/main/sif_downscaling_openEO_CDSE/udf/udf_sif_downscaling.py). Then we can call the ```udf``` using:


```{python}
udf_sif_prediction = openeo.UDF.from_file(
    "src/udf/udf_sif_downscaling.py",
    context={"window_size_lat": 3, "window_size_lon": 3},
)

sif_downscaled = cube_to_upscale.apply_neighborhood(
    udf_sif_prediction,
    size=[
        {"dimension": "x", "value": 512, "unit": "px"},
        {"dimension": "y", "value": 512, "unit": "px"},
    ],
    overlap=[
        {"dimension": "x", "value": 0, "unit": "px"},
        {"dimension": "y", "value": 0, "unit": "px"},
    ],
)
```



It is not possible to reduce the number of bands using ```apply_neighborhood``` then we need to just select the first band:

```{python}
# removing bands that are not needed it

sif_downscaled_renamed = sif_downscaled.rename_labels(
    dimension="bands", source=["b1"], target=["SIF"]
)

sif_downscaled_renamed = sif_downscaled_renamed.band("SIF")
```

Now we can run everthing and save the results


```{python}
"""
sif_downscaled_renamed.execute_batch(
    outputfile="data/openeo_sif_downscaled.tif",
    title="SIF_downscaling",
    description="Predicting SIF at high spatial resolution"
)
"""
```

## Comparing SIF products

Comparing the original SIF product at 5 km with the Downscaled SIF at 1 km.

```{python}
sif_downscaled_local = rio.open_rasterio("data/openeo_sif_downscaled.tif")
print(sif_downscaled_local)
```

```{python}
fig, axs = plt.subplots(nrows=2, figsize=(6, 10))
cube_sif_local.plot(ax=axs[0])
axs[0].set_title("SIF (Original)")
sif_downscaled_local.plot(ax=axs[1])
axs[1].set_title("SIF (Downscaled)")

```


```{python}
plt.clf()

sif_downscaled_local.plot()

```


To validate the downscaling results let's resample the SIF downscaled and compare it with the original product at 5 km.


```{python}

sif_downscaled_resampled = sif_downscaled_renamed.resample_cube_spatial(
    target=cube_SIF_original_median,
    method="med",
)

```

```{python}
# sif_downscaled_resampled.execute_batch("data/sif_downscaled_resampled.tif")
```


```{python}
sif_downscaled_resampled_local = rio.open_rasterio("data/sif_downscaled_resampled.tif")
sif_downscaled_resampled_local
```


```{python}
fig, axs = plt.subplots(nrows=2, figsize=(6, 10))
cube_sif_local.plot(ax=axs[0])
axs[0].set_title("SIF (Original)")
sif_downscaled_resampled_local.plot(ax=axs[1])
axs[1].set_title("SIF (Downscaled) resampled")

plt.tight_layout()
```

Now let's do $originalSIF - upscaledSIF$

```{python}
plt.clf()
differences = cube_sif_local - sif_downscaled_resampled_local
differences.plot()
```

